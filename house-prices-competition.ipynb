{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import additional libraries that I plan on using**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# more imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load training and test datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ntrain = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"81 columns!\n\nLots of missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Take a look at SalePrice**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['SalePrice'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations:\n* The max is way higher than the 75th percentile\n* Standard deviation seems pretty high\n* There could be outliers that will mess with regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualize the distribution of SalePrice**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['SalePrice'])\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations:\n* Asymmetric distribution\n* Right tail is really long\n* Most of the houses cost around $200,000 but there are some really expensive houses in the dataset"},{"metadata":{},"cell_type":"markdown","source":"**Check the skewness value**\n* Skewed to the right\n* Linear regression assumes normally distributed data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Skewness = ',train['SalePrice'].skew())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a correlation map**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\n\nplt.figure(figsize=(15,12))\n\nsns.heatmap(corr)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Highly correlated variables (some of these are extremely obvious)\n* TotRmsAbvGrd and GrLivArea\n* GarageYrBlt and YearBuilt\n* 1stFlrSF and TotalBsmtSF\n* OverallQual and SalePrice\n* GarageCars and GarageArea"},{"metadata":{},"cell_type":"markdown","source":"## SalePrice Correlation"},{"metadata":{},"cell_type":"markdown","source":"**List the variables that are most correlated with SalePrice**"},{"metadata":{"trusted":true},"cell_type":"code","source":"top10_corr = corr['SalePrice'].sort_values(ascending=False)[:10]\ntop_features = top10_corr.index[1:]  # store top_features for later\n\ntop10_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scatterplots"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top features and SalePrice\nfig,ax = plt.subplots(nrows = 9,ncols = 1,figsize = (5, 25))\nfor i in range(len(top_features)):    \n\n    ax[i].scatter(x = train[top_features[i]], y = train['SalePrice'])\n    ax[i].set_xlabel('%s'%(top_features[i]))\n    ax[i].set_ylabel('SalePrice')\n\nplt.tight_layout()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are definitely some outliers\n* A few of the scatterplots have two or three dots siting in the bottom right\n* Must be removed in order to create an accurate model"},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning/Processing"},{"metadata":{},"cell_type":"markdown","source":"**Identify and drop outliers**\n* There could be better ways to deal with outliers but dropping them is simple and effective\n* "},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = []\nQ3 = []\nLower_bound = []\nUpper_bound = []\nOutliers = []\n\n\nfor i in top_features:\n    \n    # 25th and 75th percentiles\n    q1, q3 = np.percentile(train[i],25), np.percentile(train[i],75)\n    # Interquartile range\n    iqr = q3 - q1\n    # Outlier cutoff\n    cut_off = 1.5*iqr\n    # Lower and Upper bounds\n    lower_bound = q1-cut_off\n    upper_bound = q3+cut_off\n        \n    # save outlier indexes\n    outlier = [x for x in train.index if train.loc[x,i]<lower_bound or train.loc[x,i]>upper_bound]\n    \n    # append values\n    Q1.append(q1)\n    Q3.append(q3)\n    Lower_bound.append(lower_bound)\n    Upper_bound.append(upper_bound)\n    Outliers.append(len(outlier))\n    \n    # drop outliers\n    train.drop(outlier,inplace=True,axis=0)\n\ndf_out = pd.DataFrame({'Column':top_features,'Q1':Q1,'Q3':Q3,'Lower bound':Lower_bound,'Upper bound':Upper_bound,'No. of outliers':Outliers})    \ndf_out.sort_values(by='No. of outliers',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Transformation"},{"metadata":{},"cell_type":"markdown","source":"**Combine and process the training and test datasets**\n* Keep track of number of rows in the training dataframe\n* Drop the Id column because it doesn't help predict SalePrice\n* Log transform SalePrice to reduce skewness (store it in target)\n* Drop SalePrice from the training data because it's not in the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of rows\nnrows = train.shape[0]\n\n# log transform SalePrice\ntarget = np.log(train['SalePrice'])\n\n# visualize SalePrice again\nsns.distplot(target)\nplt.xticks(rotation=0);\n\n# drop Id and SalePrice from train dataframe\ntrain.drop(['Id','SalePrice'],inplace=True,axis=1)\n\n# store test Id\ntest_id = test['Id']\n\n# drop test Id\ntest.drop(['Id'],inplace=True,axis=1)\n\n# concatenate train and test dataframes\ntrain = pd.concat([train,test])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of SalePrice is roughly normal now after the log transformation"},{"metadata":{},"cell_type":"markdown","source":"**Examine missing data**\n* Null doesn't mean not important"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Null values\ntrain.isna().sum().sort_values(ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding\n* Replace ordinal variables with appropriate numbers\n* Replace null categoorical variables with \"other\" or \"typical\"\n* Replace numerical variables with either 0, the median, or the mode, depending on data_description.txt"},{"metadata":{},"cell_type":"markdown","source":"### Ordinal Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ex\tExcellent\n# Gd\tGood\n# TA\tAverage/Typical\n# Fa\tFair\n# NA\tNo Pool\ntrain['PoolQC'].replace(['Ex','Gd','TA','Fa',np.nan],[4,3,2,1,0],inplace=True)\n\n# GdPrv\tGood Privacy\n# MnPrv\tMinimum Privacy\n# GdWo\tGood Wood\n# MnWw\tMinimum Wood/Wire\n# NA\tNo Fence\ntrain['Fence'].replace(['GdPrv','MnPrv','GdWo','MnWw',np.nan],[4,3,2,1,0],inplace=True)\n\n# Ex\tExcellent - Exceptional Masonry Fireplace\n# Gd\tGood - Masonry Fireplace in main level\n# TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n# Fa\tFair - Prefabricated Fireplace in basement\n# Po\tPoor - Ben Franklin Stove\n# NA\tNo Fireplace\ntrain['FireplaceQu'].replace(['Ex','Gd','TA','Fa','Po',np.nan],[5,4,3,2,1,0],inplace=True)\n\n\n# Ex\tExcellent\n# Gd\tGood\n# TA\tTypical/Average\n# Fa\tFair\n# Po\tPoor\n# NA\tNo Garage\nfor i in ['GarageCond','GarageQual']:\n    train[i].replace(['Ex','Gd','TA','Fa','Po',np.nan],[5,4,3,2,1,0],inplace=True)\n    \n# Ex\tExcellent\n# Gd\tGood\n# TA\tTypical\n# Fa\tFair\n# Po\tPoor\n# NA\tNo Basement\nfor i in ['BsmtCond','BsmtQual']:\n    train[i].replace(['Ex','Gd','TA','Fa','Po',np.nan],[5,4,3,2,1,0],inplace=True)\n\n# Gd\tGood Exposure\n# Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n# Mn\tMimimum Exposure\n# No\tNo Exposure\n# NA\tNo Basement\ntrain['BsmtExposure'].replace(['Gd','Av','Mn','No',np.nan],[4,3,2,1,0],inplace=True)\n\n# GLQ\tGood Living Quarters\n# ALQ\tAverage Living Quarters\n# BLQ\tBelow Average Living Quarters\n# Rec\tAverage Rec Room\n# LwQ\tLow Quality\n# Unf\tUnfinshed\n# NA\tNo Basement\nfor i in ['BsmtFinType1','BsmtFinType2']:\n    train[i].replace(['GLQ','ALQ','BLQ','Rec','LwQ','Unf',np.nan],[6,5,4,3,2,1,0],inplace=True)  \n\n# N\tNo\n# Y\tYes\ntrain['CentralAir'].replace(['N','Y'],[0,1],inplace=True)\n\n# Ex\tExcellent\n# Gd\tGood\n# TA\tAverage/Typical\n# Fa\tFair\n# Po\tPoor\nfor i in ['HeatingQC','ExterCond','ExterQual']:\n    train[i].replace(['Ex','Gd','TA','Fa','Po'],[4,3,2,1,0],inplace=True)\n\n# Ex\tExcellent\n# Gd\tGood\n# TA\tTypical/Average\n# Fa\tFair\n# Po\tPoor\ntrain['KitchenQual'].replace(['Ex','Gd','TA','Fa','Po'],[4,3,2,1,0],inplace=True)\n\n# Replace NA with most mode (because NA doesn't mean no kitchen)\ntrain['KitchenQual'].fillna(train['KitchenQual'].mode()[0],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace NA with \"None\" for categorical features\n* Useful for One Hot Encoding later"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NA means no miscellaneous feature\ntrain['MiscFeature'].fillna('None',inplace=True)\n\n# NA means no alley access\ntrain['Alley'].fillna('None',inplace=True)\n\n# NA means no garage\nfor i in ['GarageFinish','GarageType']:\n    train[i].fillna('None',inplace=True) \n    \n# NA means no masonry work\ntrain['MasVnrType'].fillna('None',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace null lotfrontage with average of the neighborhood\ntrain['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(lambda x:x.fillna(x.median()))\n\nfor i in ['GarageYrBlt','GarageCars','GarageArea']:\n     train[i].fillna(0,inplace=True)\n        \nfor i in ['BsmtHalfBath','BsmtFullBath','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']:\n    train[i].fillna(0,inplace=True)\n    \n# If no masonary work, then area is 0\ntrain['MasVnrArea'].fillna(0,inplace=True)\n\n# Replace with the most common value\nfor i in ['MSZoning','Utilities']:\n    train[i].fillna(train[i].mode()[0],inplace=True)\n\n# data_description says \"assume typical unless deductions are warranted\"\ntrain['Functional'].fillna('Typ',inplace=True)\n\n# Assume SaleType is 'Other' if null\ntrain['SaleType'].fillna('Oth',inplace=True)\n\n#Replace with most common value\ntrain['Electrical'].fillna(train['Electrical'].mode()[0],inplace=True)\n\n# Replace null with 'Other'\nfor i in ['Exterior1st','Exterior2nd']:\n    train[i].fillna('Other',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create New Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boolean features\ntrain['HasPool'] = train['PoolArea'].apply(lambda x: 1 if x>0 else 0)\ntrain['HasFirePlace'] = train['FireplaceQu'].apply(lambda x: 1 if x>0 else 0)\ntrain['HasFence'] = train['Fence'].apply(lambda x: 1 if x>0 else 0)\ntrain['HasMsonary'] = train['MasVnrArea'].apply(lambda x: 1 if x>0 else 0)\ntrain['HasGarage'] = train['GarageArea'].apply(lambda x: 1 if x>0 else 0)\ntrain['HasBsmt'] = train['TotalBsmtSF'].apply(lambda x: 1 if x>0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total surface area of house\ntrain['TotalSF'] = train.apply(lambda x: x['1stFlrSF'] + x['2ndFlrSF'] + x['TotalBsmtSF'], axis=1)\n\n# Total number of bathrooms in the house\ntrain['TotalBath'] = train.apply(lambda x: x['FullBath'] + 0.5*x['HalfBath'] + x['BsmtFullBath'] + 0.5*x['BsmtHalfBath'], axis=1)\n\n# Total Porch area in the house\ntrain['TotalPorch'] = train.apply(lambda x: x['OpenPorchSF'] + x['EnclosedPorch'] + x['3SsnPorch'] + x['ScreenPorch'], axis=1)\n\n# New house or an old house\ntrain['NewHouse'] = train.apply(lambda x: 1 if x['SaleCondition']=='Partial' else 0, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert categorical data ainto numbers to prepare for regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-Hot/Dummy encoding\ntrain = pd.get_dummies(train,drop_first=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seperate the training and test datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train dataset\ndf = train.iloc[:nrows,:]\n\n# test dataset\ntest = train.iloc[nrows:,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split the training dataset up**\n* So that I can train the model without using the test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df\ny = target\n\n# training and validation set\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=27)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attempt #1: Linear Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nlr = LinearRegression()\n\nlr.fit(X_train,y_train)\n\nrmse = np.sqrt(mean_squared_error(y_test,lr.predict(X_test)))  # use RMSE because the competition scores using RMSE\nprint(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"Score is good, but it can be better\""},{"metadata":{},"cell_type":"markdown","source":"# Attempt #2: Ridge Regression Model\n*'This is another one of the types of regression in machine learning which is usually used when there is a high correlation between the independent variables'*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\n# different alpha values\nalphas = [0.01, 0.1, 0.3, 1, 3, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100]  # alpha is the regularization strength\n\ndef calcRMSE(a):\n    lr = Ridge(alpha=a)\n    \n    lr.fit(X_train,y_train)\n    \n    rmse = np.sqrt(mean_squared_error(y_test,lr.predict(X_test)))\n    \n    return rmse\n    \nfor a in alphas:\n    print('For Alpha = ',a,', RMSE = ',calcRMSE(a))\n\n\n# Find the alpha that produces the lowest RMSE\nvals = {}\nfor i in range(1, 100):\n    vals[i] = calcRMSE(i)\n    \noptimalAlpha = min(vals, key=vals.get)\nprint(\"Optimal alpha value =\", optimalAlpha)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit the data using Ridge Regression with the alpha from the previous step**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Ridge(alpha=optimalAlpha)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exponentiate the predicted values for SalePrice (because it was log transformed earlier)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_pred = model.predict(test)\nactual_pred = np.exp(log_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submit the predictions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict = {'Id':test_id,'SalePrice':actual_pred}\n\nsubmit = pd.DataFrame(data_dict)\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![Final score](https://i.ibb.co/ryGdff7/image.png)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}